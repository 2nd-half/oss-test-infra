{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d0b60ef-8c3c-4246-b87b-2d2ca1f0f302",
   "metadata": {},
   "source": [
    "# Fine-tuning BERT to answer SQuAD questions using TensorFlow2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59032120-8669-4276-bab9-a58f5ae80849",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5fa3ea-308d-460d-93ab-88bcc9fd304b",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to:\n",
    "\n",
    "* Download the SQuAD dataset using `tensorflow_datasets`\n",
    "* Download a pretrain BERT model using `tensorflow_hub` and its corresponding `tokenizer`\n",
    "* Process the squad dataset to:\n",
    "  - Tokenize the contexts and questions\n",
    "  - Pack each context+question pair into a tensorflow BERT input with\n",
    "  - Identify the start and end token in the context\n",
    "  - Convert the start/end context token index into the expected outputs\n",
    "* Construct a model which converts the input into output predictions\n",
    "* Choose a loss for each output\n",
    "* Use the predictions to print out the answer\n",
    "  - Find the highest probability start and end index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98536a1-bb6c-4eb7-8796-1eae29070c04",
   "metadata": {},
   "source": [
    "#### Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d7775a-cf6c-4bab-817c-1a10f6a53806",
   "metadata": {},
   "source": [
    "- [Setup notebook](#Setup-Notebook)\n",
    "- [Setup dependencies](#Setup-dependencies)\n",
    "- [Tokenizer](#Tokenizer)\n",
    "- [Dataset](#Dataset)\n",
    "- [Model](#Model)\n",
    "- [Train](#Train)\n",
    "- [Export](#Export)\n",
    "- [Evaluate](#Evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ea928-07d6-4103-aca3-b79959b4fb2e",
   "metadata": {},
   "source": [
    "## Setup notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a3461-e410-42bb-8259-12442fdd46af",
   "metadata": {},
   "source": [
    "Back to [Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae6b11-75d6-487c-a440-5ee1fb7bd5a9",
   "metadata": {},
   "source": [
    "First you will need a machine with jupyter installed as well as a GPU/TPU.\n",
    "\n",
    "One option to consider is to use [Google Colaboratory](https://research.google.com/colaboratory/).\n",
    "\n",
    "This notebook was created with a [user-managed notebook](https://cloud.google.com/vertex-ai/docs/workbench/user-managed/create-new#gcloud) on Google Cloud's Vertex AI platform.\n",
    "\n",
    "Create a notebook in your own project by going to https://notebook.new/ or else customizing the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7807d1c-29ef-40c7-8e73-0676fbf8de51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the following command:\n",
      "  gcloud notebooks instances create MY_INSTANCE_NAME \\\n",
      "    --project=MY_PROJECT_ID \\\n",
      "    --vm-image-project=deeplearning-platform-release \\\n",
      "    --vm-image-family=tf-ent-2-8-cu113-notebooks \\\n",
      "    --machine-type=n1-standard-8 \\\n",
      "    --location=us-central1-a \\\n",
      "    --accelerator_type=CHOOSE \\\n",
      "    --accelerator_cores=1\n"
     ]
    }
   ],
   "source": [
    "vm_image_project='deeplearning-platform-release'\n",
    "vm_image_family='tf-ent-2-8-cu113-notebooks'\n",
    "machine_type='n1-standard-8'\n",
    "location='us-central1-a'\n",
    "accelerator_type='CHOOSE' # eg, 'NVIDIA_TESLA_V100'\n",
    "accelerator_cores=1\n",
    "\n",
    "project='MY_PROJECT_ID'\n",
    "instance_name='MY_INSTANCE_NAME'\n",
    "print('Run the following command:')\n",
    "print(' \\\\\\n    '.join([\n",
    "    f'  gcloud notebooks instances create {instance_name}',\n",
    "    f'--project={project}',\n",
    "    f'--vm-image-project={vm_image_project}',\n",
    "    f'--vm-image-family={vm_image_family}',\n",
    "    f'--machine-type={machine_type}',\n",
    "    f'--location={location}',\n",
    "    f'--accelerator_type={accelerator_type}',\n",
    "    f'--accelerator_cores={accelerator_cores}',\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec20e436-b155-4935-b9da-9daf889e3792",
   "metadata": {},
   "source": [
    "Remember that these machines are expensive, many hundreds of dollars a month. So make sure you stop the VM when you are not using it, either at the [Vertex AI workbench](https://console.cloud.google.com/vertex-ai/workbench/list/instances) or else using `gcloud`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156798d7-477c-400d-b4f7-b0f976468a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop your notebook:\n",
      "  gcloud notebooks instances stop MY_INSTANCE_NAME --project=MY_PROJECT_ID --location=us-central1-a\n",
      "Delete your notebook:\n",
      "  gcloud notebooks instances delete MY_INSTANCE_NAME --project=MY_PROJECT_ID --location=us-central1-a\n"
     ]
    }
   ],
   "source": [
    "print('Stop your notebook:')\n",
    "print(f'  gcloud notebooks instances stop {instance_name} --project={project} --location={location}')\n",
    "print('Delete your notebook:')\n",
    "print(f'  gcloud notebooks instances delete {instance_name} --project={project} --location={location}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5dfaa3-1f05-4cba-9a9d-388a8d9daf52",
   "metadata": {},
   "source": [
    "After creating the notebook:\n",
    "1) head over to the Vertex AI [workbench](https://console.cloud.google.com/vertex-ai/workbench/list/instances)\n",
    "2) Wait for the `OPEN JUPYTERLAB` button to appear next the `MY_INSTANCE_NAME` you chose\n",
    "3) Click on the button.\n",
    "\n",
    "This should open JupyterLab, showing you a launcher tab. Click `File -> New Launcher` to create another one.\n",
    "\n",
    "On the left side there should be a few buttons, one of which is a folder icon. Clicking this will close/open the file browser on the left sidebar.\n",
    "\n",
    "This file browser should have a `+` button (which creates a new launcher tab) as well as an up arrow, which allows you to upload files. \n",
    "\n",
    "Click the upload button and upload this `.ipynb` python notebook. After uploading it should now appear in your file list.\n",
    "\n",
    "Double-click the file you uploaded in the browser, and it should open this notebook. You are ready to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c3750-f132-44c7-bdc9-1111a64edb2e",
   "metadata": {},
   "source": [
    "## Setup dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f14564-e81e-4973-b722-6dbd167b8a6b",
   "metadata": {},
   "source": [
    "Back to [Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a6e1f5-564a-4322-9daf-f2813a80f01f",
   "metadata": {},
   "source": [
    "Make sure the following packages are installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c25956f0-158c-4c3a-8669-d0e9ba0270c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-text==2.8.*\n",
      "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-text==2.8.*) (0.12.0)\n",
      "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-text==2.8.*) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.1.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (13.0.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.21.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.24.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.14.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.6.3)\n",
      "Requirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.5.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.44.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0rc0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (59.8.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.19.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.37.1)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.5.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.27.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.11.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.2.0)\n",
      "Installing collected packages: tensorflow-text\n",
      "Successfully installed tensorflow-text-2.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"tensorflow-text==2.8.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dab3a9a1-74d8-4bbf-a952-bd9e90e9e54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-models-official==2.7.1\n",
      "  Downloading tf_models_official-2.7.1-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gin-config\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.7.1) (1.21.5)\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.7.1) (9.0.1)\n",
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.8/99.8 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kaggle>=1.3.9\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tf-slim>=1.1.0\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sacrebleu\n",
      "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.7.1) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.7.1) (3.5.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.7.1) (1.7.3)\n",
      "Requirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.7.1) (4.4.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.7.1) (0.12.0)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.7.1) (5.9.0)\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.22.0 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.7.1) (1.3.5)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.7.1) (2.41.0)\n",
      "Requirement already satisfied: tensorflow-text>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.7.1) (2.8.2)\n",
      "Collecting Cython\n",
      "  Using cached Cython-0.29.28-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "Requirement already satisfied: oauth2client in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.7.1) (4.1.3)\n",
      "Collecting tensorflow-model-optimization>=0.4.1\n",
      "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.6/237.6 KB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorflow>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.7.1) (2.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.7.1) (6.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.1) (0.20.4)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.1) (4.1.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.1) (2.5.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.1) (2.6.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.1) (0.1.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official==2.7.1) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official==2.7.1) (2.8.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official==2.7.1) (2.27.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official==2.7.1) (4.63.0)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official==2.7.1) (6.1.1)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official==2.7.1) (1.26.8)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.22.0->tf-models-official==2.7.1) (2021.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (1.0.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (13.0.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (2.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (2.8.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (3.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (0.2.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (2.8.0rc0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (1.44.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (59.8.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (0.5.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (3.19.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (0.24.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.4.0->tf-models-official==2.7.1) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.7.1) (0.1.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->tf-models-official==2.7.1) (1.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->tf-models-official==2.7.1) (3.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->tf-models-official==2.7.1) (4.30.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->tf-models-official==2.7.1) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->tf-models-official==2.7.1) (21.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.7/site-packages (from oauth2client->tf-models-official==2.7.1) (0.2.7)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from oauth2client->tf-models-official==2.7.1) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from oauth2client->tf-models-official==2.7.1) (4.8)\n",
      "Collecting regex\n",
      "  Downloading regex-2022.4.24-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m749.7/749.7 KB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting portalocker\n",
      "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu->tf-models-official==2.7.1) (0.4.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval->tf-models-official==2.7.1) (1.0.2)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official==2.7.1) (0.3.4)\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official==2.7.1) (1.7.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official==2.7.1) (0.18.2)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official==2.7.1) (5.4.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official==2.7.1) (21.4.0)\n",
      "Requirement already satisfied: promise in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official==2.7.1) (2.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow>=2.4.0->tf-models-official==2.7.1) (0.37.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.7.1) (1.54.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.7.1) (5.0.0)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow>=2.4.0->tf-models-official==2.7.1) (1.5.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle>=1.3.9->tf-models-official==2.7.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle>=1.3.9->tf-models-official==2.7.1) (2.0.12)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.7.1) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.7.1) (3.1.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.4.0->tf-models-official==2.7.1) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.4.0->tf-models-official==2.7.1) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.4.0->tf-models-official==2.7.1) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.4.0->tf-models-official==2.7.1) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.4.0->tf-models-official==2.7.1) (0.6.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources->tensorflow-datasets->tf-models-official==2.7.1) (3.7.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.7/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.7.1) (1.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.4.0->tf-models-official==2.7.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.4.0->tf-models-official==2.7.1) (4.11.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.4.0->tf-models-official==2.7.1) (3.2.0)\n",
      "Building wheels for collected packages: kaggle, py-cpuinfo, pycocotools, seqeval\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=f66be94e936ca6ed5e4a7354f6ccc5dcd295f90a1d4c0f283728d50dd9d05ea1\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=c412bdeeabd35481e09702c3ab0834210f39c0c0015057f629022db6cd6dd026\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
      "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp37-cp37m-linux_x86_64.whl size=326664 sha256=0ec508078c33b1e76b31644ee7563692e76109344f307b222c3529938935b32d\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/a3/5f/fa/f011e578cc76e1fc5be8dce30b3eb9fd00f337e744b3bba59b\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=c8f0590f791018c7f7c62e4b02aa6a9ad46975d8c00164fa877813898a525b17\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
      "Successfully built kaggle py-cpuinfo pycocotools seqeval\n",
      "Installing collected packages: tabulate, sentencepiece, py-cpuinfo, gin-config, typeguard, regex, portalocker, opencv-python-headless, Cython, tf-slim, tensorflow-model-optimization, tensorflow-addons, sacrebleu, kaggle, seqeval, pycocotools, tf-models-official\n",
      "Successfully installed Cython-0.29.28 gin-config-0.5.0 kaggle-1.5.12 opencv-python-headless-4.5.5.64 portalocker-2.4.0 py-cpuinfo-8.0.0 pycocotools-2.0.4 regex-2022.4.24 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tabulate-0.8.9 tensorflow-addons-0.16.1 tensorflow-model-optimization-0.7.2 tf-models-official-2.7.1 tf-slim-1.1.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "# tf-models-official 2.8.0 produces a official.nlp.bert.configs below for some reasons, so use the previous version.\n",
    "!pip install tf-models-official==2.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7faad0-075c-49bc-ae22-b70fb0901865",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /opt/conda/lib/python3.7/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /opt/conda/lib/python3.7/site-packages (from pydot) (3.0.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "783ecfc4-9dd4-4505-a04e-f3db2e1b509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not get lock /var/lib/dpkg/lock-frontend - open (11: Resource temporarily unavailable)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), is another process using it?\n"
     ]
    }
   ],
   "source": [
    "!sudo apt install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d6e5a-854b-4e38-bbee-b8d104e1344c",
   "metadata": {},
   "source": [
    "Now you can import all of the python modules that this notebook depends on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3885539-011c-4d5f-8360-bac0366af2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "from official.modeling import tf_utils\n",
    "from official import nlp\n",
    "from official.nlp import bert\n",
    "\n",
    "# Load the required submodules\n",
    "from official.nlp import optimization\n",
    "import official.nlp.bert.bert_models\n",
    "import official.nlp.bert.configs\n",
    "import official.nlp.bert.run_classifier\n",
    "import official.nlp.bert.tokenization\n",
    "import official.nlp.data.classifier_data_lib\n",
    "import official.nlp.modeling.losses\n",
    "import official.nlp.modeling.models\n",
    "import official.nlp.modeling.networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0755b4e-85c0-4d31-814a-670884044867",
   "metadata": {},
   "source": [
    "Additional imports that may be necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2169021b-9f45-4d12-b478-a4c79e2d787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_text as text  # A dependency of the preprocessing model\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7125bb66-85c5-4a66-91e5-0df82ff05530",
   "metadata": {},
   "source": [
    "A couple different strategies to use to distribute work, also helps move up some TF debug spew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ec6006-cafa-4cbf-85fb-1dfea82602b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_strategy = tf.distribute.get_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fdabe7d-e5b4-4ae2-bde6-2651613157bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 01:03:35.817084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 01:03:35.986496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 01:03:35.987173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 01:03:35.988722: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-01 01:03:35.992886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 01:03:35.993807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 01:03:35.994527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 01:03:38.138806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 01:03:38.139570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 01:03:38.140227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-01 01:03:38.141784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14668 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "if os.environ.get('COLAB_TPU_ADDR'):\n",
    "  cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
    "  tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "  tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "  strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
    "  print('Using TPU')\n",
    "elif tf.config.list_physical_devices('GPU'):\n",
    "  # https://www.tensorflow.org/guide/distributed_training\n",
    "  strategy = tf.distribute.MirroredStrategy()\n",
    "  # TODO(fejta): strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "  # TODO(fejta): default_strategy = tf.distribute.get_strategy()\n",
    "  print('Using GPU')\n",
    "else:\n",
    "  raise ValueError('Running on CPU is not recommended.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7189bf8e-8a2e-4b42-9bb8-51eed79116db",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01de049f-1ccf-4a8b-b855-383643fd4115",
   "metadata": {},
   "source": [
    "Back to [Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9c6367-10c0-4d80-990c-32889cfe5e0e",
   "metadata": {},
   "source": [
    "First let's download the BERT model we wil use. The [Choose a BERT model to fine-tune](https://www.tensorflow.org/text/tutorials/bert_glue#choose_a_bert_model_to_fine-tune) section of the GLUE fine-tuning (and similar tf BERT docs) contain a `Toggle code` button that lists other encoder/preprocessing pairs.\n",
    "\n",
    "Let's choose the one with hyperparamers that match the BERT paper: 12 layers, 768 hidden features, 12 attention heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "613f3b42-d6f2-44f2-9686-0e991ad42309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select pretrained bert model\n",
      "  https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\n",
      "Files in gs://cloud-tpu-checkpoints/bert/v3/uncased_L-12_H-768_A-12\n",
      "  bert_config.json\n",
      "  bert_model.ckpt.data-00000-of-00001\n",
      "  bert_model.ckpt.index\n",
      "  vocab.txt\n"
     ]
    }
   ],
   "source": [
    "print('Select pretrained bert model')\n",
    "# Pre-trained model\n",
    "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n",
    "# Matching encoder\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "print(' ', tfhub_handle_encoder)\n",
    "\n",
    "gs_folder_bert = \"gs://cloud-tpu-checkpoints/bert/v3/uncased_L-12_H-768_A-12\"\n",
    "print('Files in', gs_folder_bert)\n",
    "gs_files = tf.io.gfile.listdir(gs_folder_bert)\n",
    "print(' ', '\\n  '.join(gs_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb8f22-73e0-4a41-8251-ba6c054b77df",
   "metadata": {},
   "source": [
    "The `tfhub_handle_preprocess` does one-way preprocessing, which is going to be hard to work with. The SQuAD dataset returns a start index as well as the answer text. We will need to identify the matching tokens in the text and their start/end index.\n",
    "\n",
    "Additionally, when we get predictions we will need to be able to convert a list of tokens back into text. Using [the BERT tokenizer](https://www.tensorflow.org/text/tutorials/fine_tune_bert#the_bert_tokenizer) section from the Fine-tuning BERT documentation provides a better way to do this, which we will copy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c79a853b-0365-41a8-80f1-944a7830045c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create reversible tokenizer\n"
     ]
    }
   ],
   "source": [
    "print('Create reversible tokenizer')\n",
    "tokenizer = bert.tokenization.FullTokenizer(\n",
    "    vocab_file=os.path.join(gs_folder_bert, \"vocab.txt\"),\n",
    "     do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269fece-0f32-4d4b-9f04-2ed7ded8818e",
   "metadata": {},
   "source": [
    "Let's define a couple helper functions to help us go between strings and tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74ed2079-3a86-4fd6-ad76-51eb03b528d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_token_ids(s):\n",
    "    \"\"\"Converts 'FUN stuffing' into ['fun', 'stuff', '##ing'] and then [7, 2089, 88].\"\"\"\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(s))\n",
    "\n",
    "def from_token_ids(ids, lossy=True):\n",
    "    \"\"\"Converts [7, 2089, 88] into ['fun', 'stuff', '##ing'] and then 'fun stuff ##ing' or 'fun stuffing'.\"\"\"\n",
    "    s = ' '.join(tokenizer.convert_ids_to_tokens(ids))\n",
    "    if lossy:\n",
    "        s = s.replace('[CLS] ', '').replace(' [PAD]', '').replace(' [SEP]', '\\n\\n').replace(' ##', '')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab41ee-31a7-4a05-9e84-7b996b30a73c",
   "metadata": {},
   "source": [
    "Now let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77baf4e4-12c8-4f21-b3c7-f8b4aa99c496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String to token id list:\n",
      "This is a very interesting sentence. becomes: [2023, 2003, 1037, 2200, 5875, 6251, 1012]\n",
      "Token ids to string:\n",
      "[2023, 2003, 1037, 2200, 5875, 6251, 1012] becomes: this is a very interesting sentence .\n"
     ]
    }
   ],
   "source": [
    "print('String to token id list:')\n",
    "orig = 'This is a very interesting sentence.'\n",
    "ids = to_token_ids(orig)\n",
    "print(orig, 'becomes:', ids)\n",
    "print('Token ids to string:')\n",
    "s = from_token_ids(ids)\n",
    "print(ids, 'becomes:', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04b31d-1ae0-4c07-ba36-a919933895c0",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0d3a0-2eee-4ad0-85ac-730c3c0d059a",
   "metadata": {},
   "source": [
    "Back to [Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774f445d-ac66-4795-b18c-e3d1c0904702",
   "metadata": {},
   "source": [
    "The [SQuAD dataset](https://rajpurkar.github.io/SQuAD-explorer/) is a popular dataset that tests reading comprehension. People are given a wikipedia paragraph and a question about it. The goal is to highlight the correct answer in the text. \n",
    "\n",
    "The BERT paper mentions this as one of the fine-tuning exercises it does very well on, We will now try and replicate its results.\n",
    "\n",
    "The `tensorflow_datasets` module [includes](https://www.tensorflow.org/datasets/catalog/squad) squad, which makes it easy to download and prepare for training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9666c6d4-2763-4a3f-81a6-1f7742ee3afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load squad from tfds...\n",
      "\u001b[1mDownloading and preparing dataset 33.51 MiB (download: 33.51 MiB, generated: 94.06 MiB, total: 127.58 MiB) to /home/jupyter/tensorflow_datasets/squad/v1.1/3.0.0...\u001b[0m\n",
      "\u001b[1mDataset squad downloaded and prepared to /home/jupyter/tensorflow_datasets/squad/v1.1/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py:622: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.get_single_element()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py:622: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.get_single_element()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Load squad from tfds...')\n",
    "out = tfds.load('squad/v1.1', with_info=True, batch_size=-1) # -1 means whole dataset in mem\n",
    "squad, info = out\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffeb678-a94a-4eea-8480-f8073159074c",
   "metadata": {},
   "source": [
    "Let's take a look at what we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f271ecc4-0d09-421b-b991-4676d37b865f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys([Split('train'), Split('validation')]),\n",
       " dict_keys(['answers', 'context', 'id', 'question', 'title']))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad.keys(), squad['train'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "292fd574-8096-455e-9041-2dc241dc0775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='squad',\n",
      "    full_name='squad/v1.1/3.0.0',\n",
      "    description=\"\"\"\n",
      "    Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\n",
      "    \"\"\",\n",
      "    config_description=\"\"\"\n",
      "    Version 1.1.0 of SQUAD\n",
      "    \"\"\",\n",
      "    homepage='https://rajpurkar.github.io/SQuAD-explorer/',\n",
      "    data_path='/home/jupyter/tensorflow_datasets/squad/v1.1/3.0.0',\n",
      "    download_size=33.51 MiB,\n",
      "    dataset_size=94.06 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'answers': Sequence({\n",
      "            'answer_start': tf.int32,\n",
      "            'text': Text(shape=(), dtype=tf.string),\n",
      "        }),\n",
      "        'context': Text(shape=(), dtype=tf.string),\n",
      "        'id': tf.string,\n",
      "        'question': Text(shape=(), dtype=tf.string),\n",
      "        'title': Text(shape=(), dtype=tf.string),\n",
      "    }),\n",
      "    supervised_keys=None,\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'train': <SplitInfo num_examples=87599, num_shards=1>,\n",
      "        'validation': <SplitInfo num_examples=10570, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{2016arXiv160605250R,\n",
      "           author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\n",
      "                     Konstantin and {Liang}, Percy},\n",
      "            title = \"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\",\n",
      "          journal = {arXiv e-prints},\n",
      "             year = 2016,\n",
      "              eid = {arXiv:1606.05250},\n",
      "            pages = {arXiv:1606.05250},\n",
      "    archivePrefix = {arXiv},\n",
      "           eprint = {1606.05250},\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc66cb-761f-43ce-94ac-f0ac40a7b575",
   "metadata": {},
   "source": [
    "We will need to encode each question into the format expected by bert. This involves tokenizing the question and context, converting the tokens into numbers and then also including the word type and word mask inputs as well.\n",
    "\n",
    "The GLUE fine-tuning tutorial shows how to do this dynamically with as part of the keras/tensorflow graph, but this seems takes up enough GPU ram that shrinks the batch size and increases training time. It also makes it harder to figure out the correct start/end index to train on.\n",
    "\n",
    "So instead we are going to preprocess everything so that the input and expected outputs are easy to obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8206dfe3-1a1c-43f3-a188-6c3a4c4e3a0d",
   "metadata": {},
   "source": [
    "A fun thing about SQuAD is that it appears to have been created by paying people to write questions. A small percentage of them are hilariously bad. For example here's one bad question:\n",
    "> I couldn't could up with another question. But i need to fill this space because I can't submit the hit. \n",
    "\n",
    "There are also issues where the answer might be `2` and the dataset indicates the first character of `2019`, but the tokizer is usually word or word-piece based, not character based. So we won't find the correct answer at this location.\n",
    "\n",
    "This is a small part of the data, so I set up some infrastructure to patch it with better answers, but eventually got bored. So now we'll just identify these as `SKIP` examples and then filter them out of the dataset we train/validate on.\n",
    "\n",
    "Something to improve if you can!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "767faeb5-2146-4e1d-8b56-c53acb9e1547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(t):\n",
    "    \"\"\"Decode a tensor string into printable one.\"\"\"\n",
    "    return t.numpy().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2b39109-4686-4d95-ad80-19ec3a2d0efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = {} # No patches, see -Copy1.ipynb, TODO(fejta): add these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8522414-5e31-48ca-b6a8-383dedbec95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT uses [CLS] for the start and [SEP] separates the context and question\n",
    "tok_cls, tok_sep = tokenizer.convert_tokens_to_ids(['[CLS]', '[SEP]'])\n",
    "seq_length = 384\n",
    "zeros = np.zeros(seq_length, int)\n",
    "SKIP = (zeros, zeros, zeros), (-1, -1)\n",
    "\n",
    "def tokenize_example(ex):\n",
    "    \"\"\"Returns a packed example after tokenizing the input/finding output.\"\"\"\n",
    "    context = ex['context']\n",
    "    context_txt = decode(context)\n",
    "    context_ids = to_token_ids(context_txt)\n",
    "    question_ids = to_token_ids(decode(ex['question']))\n",
    "    # TODO(fejta): handle impossible questions\n",
    "    if 'answers' not in ex:  # Probably an example we are predicting.\n",
    "        start_idx, end_idx = 0, 0\n",
    "    else:  # Try and identify the start and end index.\n",
    "        # Check if this is a patched example\n",
    "        exid = decode(ex['id'])\n",
    "        ctx_start, atext_txt = patches.get(exid, (None, None))\n",
    "        if ctx_start and ctx_start < 0:  # patch says to SKIP\n",
    "            return SKIP\n",
    "        # Now identify where the answer appears in the context.\n",
    "        atext_txt = atext_txt or decode(ex['answers']['text'][0])\n",
    "        answer_ids = to_token_ids(atext_txt)\n",
    "        if not ctx_start:\n",
    "            astart = ex['answers']['answer_start']\n",
    "            ctx_start = int(astart[0])\n",
    "            if ctx_start == 1:\n",
    "                ctx_start = 0\n",
    "        ctx_left = context_txt[:ctx_start]\n",
    "        left_ids = to_token_ids(ctx_left)\n",
    "        start_idx = len(left_ids)\n",
    "        end_idx = start_idx + len(answer_ids)\n",
    "        context_answer_ids = context_ids[start_idx:end_idx]\n",
    "        # Make sure have the answer\n",
    "        if context_answer_ids != answer_ids:\n",
    "            return SKIP           \n",
    "    return pack_example(context_ids, question_ids, start_idx, end_idx)\n",
    "\n",
    "def pack_example(context_ids, question_ids, start_idx, end_idx):\n",
    "    \"\"\"Returns a ((words, types, mask), (start, end) tuple given the inputs\"\"\"\n",
    "    # Format is [CLS, CTX1, CTX2, ..., CTXN, SEP, Q1, Q2, ..., SEP, 0, 0, ...]\n",
    "    # AKA, CLS token, context tokens, SEP token, question tokens, SEP token, padding.\n",
    "    # The CLS and SEP tokens are special tokens BERT expects.\n",
    "    # NOTE: the BERT paper puts the question before the context, but\n",
    "    # this seems easier.\n",
    "    words = [tok_cls] + context_ids + [tok_sep] + question_ids + [tok_sep]\n",
    "    # NOTE: the BERT paper does something fancier here, we just SKIP inputs that\n",
    "    # are too long for now.\n",
    "    if len(words) > seq_length:\n",
    "        return SKIP\n",
    "    # The types input distinguishes context and question.\n",
    "    types = [0] * (len(context_ids)+2) + [1] * (len(question_ids) + 1)\n",
    "    # The mask input specifies non-padding tokens.\n",
    "    masks = [1] * len(types)\n",
    "    # Padding ensures that it is exactly seq_length.\n",
    "    pad_len = seq_length - len(masks)\n",
    "    padding = [0] * pad_len\n",
    "    types += padding\n",
    "    masks += padding\n",
    "    words += padding\n",
    "    # Sanity check the input\n",
    "    assert len(words) == len(types) == len(masks) == seq_length\n",
    "    if start_idx or end_idx:\n",
    "        # Sanity check the output\n",
    "        assert start_idx >= 0 and end_idx >= 0, (start_idx, end_idx)\n",
    "        assert start_idx < seq_length\n",
    "        assert end_idx < seq_length\n",
    "        ans_start = start_idx + 1\n",
    "        ans_end = end_idx + 1\n",
    "    else:\n",
    "        ans_start = -1\n",
    "        ans_end = -1\n",
    "    return (words, types, masks), (ans_start, ans_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58cf40ce-7e03-4f20-9d36-fdbd5b53de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_examples(ds, stop=None):\n",
    "    for (i, ex) in enumerate(ds):\n",
    "        if i % 1000 == 0:\n",
    "            print(i, end=' ', flush=True)\n",
    "        if i == stop:\n",
    "            print('Stopping early')\n",
    "            break\n",
    "        yield tokenize_example(ex)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b6e6f-4a6f-4896-90f7-e4958c6a0fa4",
   "metadata": {},
   "source": [
    "##### Add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "430be82b-2f8a-4a79-8170-e025a6615bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_examples(*a, **kw):\n",
    "    \"\"\"Returns an input, output for each example in the dataset.\"\"\"\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for x, y in yield_examples(*a, **kw):\n",
    "        inputs.append(x)\n",
    "        labels.append(y)\n",
    "    i = tf.constant(inputs, tf.int32)\n",
    "    words, types, masks = tf.unstack(tf.transpose(i, [1,0,2]))\n",
    "    l = tf.constant(labels)\n",
    "    starts, ends = tf.unstack(tf.transpose(l, [1, 0]))\n",
    "    assert len(words) == len(starts)\n",
    "    return {\n",
    "        'input_word_ids': words,\n",
    "        'input_type_ids': types,\n",
    "        'input_mask': masks,\n",
    "    }, {\n",
    "        'label_start': starts,\n",
    "        'label_end': ends,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e0c6db-9ab5-4630-8988-51dc1683eb4e",
   "metadata": {},
   "source": [
    "Now let's process the dataset to generate our expected inputs and outputs.\n",
    "\n",
    "If we look into the squad dataset, we'll find a dictionary that eventually returns a tensor of keys, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcd7cecf-d0c2-485f-96fd-964ef0e18628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(87599,), dtype=string, numpy=\n",
       "array([b'What is one use that would require an antenna to receive signals in various ways at once?',\n",
       "       b'About how many counts existed in the Carolingian Empire?',\n",
       "       b'How can climate changes be determined from soil?', ...,\n",
       "       b\"Guests attending the Queen's Garden Parties will mostly likely see which room?\",\n",
       "       b'What does a candidate swear on?',\n",
       "       b'In what geographic part of Libya is Bani Walid located?'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad['train']['question']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dfce26-50af-476c-8601-4a4359e09317",
   "metadata": {},
   "source": [
    "\n",
    "Let's first pack the tensors into a dataset, which will reshape things from a single dictionary with many items in each key:\n",
    "\n",
    "```\n",
    "{\n",
    "  'x': [1,2,3,...],\n",
    "  'y': [10,11,12,...],\n",
    "}\n",
    "```\n",
    "\n",
    "Into a list of dictionaries with a single item in each key:\n",
    "\n",
    "```\n",
    "[\n",
    "  {'x': [1], 'y': [10]},\n",
    "  {'x': [2], 'y': [11]},\n",
    "  ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "864a542e-c6c8-40f0-8964-124cd454218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pack the dictionary of tensors into an iterable dataset\n"
     ]
    }
   ],
   "source": [
    "print('Pack the dictionary of tensors into an iterable dataset')\n",
    "raw_train_ds = tf.data.Dataset.from_tensor_slices(squad['train'])\n",
    "raw_valid_ds = tf.data.Dataset.from_tensor_slices(squad['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309dbb56-cacb-4618-b9f9-b19014241efb",
   "metadata": {},
   "source": [
    "Now they are in the format our processing functions from above expects, so lets generate all the inputs and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f064649a-805b-493a-a64d-b9e59bfdab30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing validation labels\n",
      "0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 Done!\n"
     ]
    }
   ],
   "source": [
    "print('Computing validation labels')\n",
    "valid_stop = None # 1000 to get started\n",
    "valid_x, valid_y = process_examples(raw_valid_ds, stop=valid_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2319cfb-1c8f-4175-bcd6-a73b968bfbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing training labels\n",
      "0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 11000 12000 13000 14000 15000 16000 17000 18000 19000 20000 21000 22000 23000 24000 25000 26000 27000 28000 29000 30000 31000 32000 33000 34000 35000 36000 37000 38000 39000 40000 41000 42000 43000 44000 45000 46000 47000 48000 49000 50000 51000 52000 53000 54000 55000 56000 57000 58000 59000 60000 61000 62000 63000 64000 65000 66000 67000 68000 69000 70000 71000 72000 73000 74000 75000 76000 77000 78000 79000 80000 81000 82000 83000 84000 85000 86000 87000 Done!\n"
     ]
    }
   ],
   "source": [
    "print('Computing training labels')\n",
    "train_stop = None # 10000 to get started\n",
    "train_x, train_y = process_examples(raw_train_ds, stop=train_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deabb23-9b73-48fe-805d-13297c07883e",
   "metadata": {},
   "source": [
    "Lets also define a function that is able to decode the input/output into a format that's easier for a person to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e25cae37-8817-431f-915f-beecc064bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_x(xs, ys=None, trueys=None, stop=None):\n",
    "    \"\"\"Decodes each x (and optional y, ground truth y) and prints it.\"\"\"\n",
    "    lastctx = None  # Try and avoid repeating the same question.\n",
    "    for i, toks in enumerate(xs['input_word_ids']):\n",
    "        toks = toks.numpy()\n",
    "        q = from_token_ids(toks)\n",
    "        ctx = q.split('\\n')[0]\n",
    "        if lastctx and lastctx == ctx:\n",
    "            q = '\\n'.join(q.split('\\n')[1:])\n",
    "        else:\n",
    "            if lastctx:\n",
    "                print('-'*40)\n",
    "            lastctx = ctx\n",
    "        if ys or trueys:\n",
    "            q = q and q[:-2]\n",
    "        if ys:\n",
    "            q += ' ' + answer(toks, ys, i)\n",
    "        if trueys:\n",
    "            a = answer(toks, trueys, i)\n",
    "            q += f' (GTRUTH: {a})'\n",
    "        print(q)\n",
    "        if i == stop:\n",
    "            break\n",
    "\n",
    "            \n",
    "def answer(toks, ys, i):\n",
    "    \"\"\"Returns the answer extracted from the input tokens.\"\"\"\n",
    "    s, e = ys['label_start'][i], ys['label_end'][i]\n",
    "    return from_token_ids(toks[s:e])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb3b0d8-c595-432c-81a3-31c314a5f71d",
   "metadata": {},
   "source": [
    "Let's check an example from each dataset split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd6cef4a-e8e3-496e-b962-ff9b4863b7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example\n",
      "================================================================================\n",
      "the difference in the above factors for the case of θ = 0 is the reason that most broadcasting ( transmissions intended for the public ) uses vertical polarization . for receivers near the ground , horizontally polarized transmissions suffer cancellation . for best reception the receiving antennas for these signals are likewise vertically polarized . in some applications where the receiving antenna must work in any position , as in mobile phones , the base station antennas use mixed polarization , such as linear polarization at an angle ( with both vertical and horizontal components ) or circular polarization .\n",
      "\n",
      " what is one use that would require an antenna to receive signals in various ways at once ? mobile phones\n",
      "----------------------------------------\n",
      "the coronation of charlemagne as emperor on christmas day 800 is regarded as a turning point in medieval history , marking a return of the western roman empire , since the new emperor ruled over much of the area previously controlled by the western emperors . it also marks a change in charlemagne ' s relationship with the byzantine empire , as the assumption of the imperial title by the carolingians asserted their equivalence to the byzantine state . there were several differences between the newly established carolingian empire and both the older western roman empire and the concurrent byzantine empire . the frankish lands were rural in character , with only a few small cities . most of the people were peasants settled on small farms . little trade existed and much of that was with the british isles and scandinavia , in contrast to the older roman empire with its trading networks centred on the mediterranean . the empire was administered by an itinerant court that travelled with the emperor , as well as approximately 300 imperial officials called counts , who administered the counties the empire had been divided into . clergy and local bishops served as officials , as well as the imperial officials called missi dominici , who served as roving inspectors and troubleshooters .\n",
      "\n",
      " about how many counts existed in the carolingian empire ? 300\n",
      "Validation example\n",
      "================================================================================\n",
      "the calvin cycle starts by using the enzyme rubisco to fix co2 into five - carbon ribulose bisphosphate ( rubp ) molecules . the result is unstable six - carbon molecules that immediately break down into three - carbon molecules called 3 - phosphoglyceric acid , or 3 - pga . the atp and nadph made in the light reactions is used to convert the 3 - pga into glyceraldehyde - 3 - phosphate , or g3p sugar molecules . most of the g3p molecules are recycled back into rubp using energy from more atp , but one out of every six produced leaves the cycle — the end product of the dark reactions .\n",
      "\n",
      " how many g3p molecules leave the cycle ? one out of every six\n",
      "----------------------------------------\n",
      "a cylindrical service module ( sm ) supported the command module , with a service propulsion engine and an rcs with propellants , and a fuel cell power generation system with liquid hydrogen and liquid oxygen reactants . a high - gain s - band antenna was used for long - distance communications on the lunar flights . on the extended lunar missions , an orbital scientific instrument package was carried . the service module was discarded just before re - entry . the module was 24 . 6 feet ( 7 . 5 m ) long and 12 . 83 feet ( 3 . 91 m ) in diameter . the initial lunar flight version weighed approximately 51 , 300 pounds ( 23 , 300 kg ) fully fueled , while a later version designed to carry a lunar orbit scientific instrument package weighed just over 54 , 000 pounds ( 24 , 000 kg ) .\n",
      "\n",
      " what type of antenna was used for communication on the lunar flights ? high - gain s - band antenna\n"
     ]
    }
   ],
   "source": [
    "print('Training example')\n",
    "print('='*80)\n",
    "decode_x(train_x,train_y, stop=1)\n",
    "print('Validation example')\n",
    "print('='*80)\n",
    "decode_x(valid_x, valid_y, stop=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1eb7c-cd39-4e1c-bc9b-714924c38f28",
   "metadata": {},
   "source": [
    "Now let's package things back up into a format that is easy to send to our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "200f088e-6197-45f1-9307-9a535b12ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices({'x': train_x, 'y': train_y})\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices({'x': valid_x, 'y': valid_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353dadb9-e60c-4a17-9b37-79db83ea6868",
   "metadata": {},
   "source": [
    "And now filter our the bad examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0696ea08-e4ad-4069-b376-578ef4fe38c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping bad examples\n"
     ]
    }
   ],
   "source": [
    "print('Dropping bad examples')\n",
    "ignore_rejects = lambda ex: ex['y']['label_end']>=0\n",
    "filt_valid_ds = valid_ds.filter(ignore_rejects)\n",
    "filt_train_ds = train_ds.filter(ignore_rejects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d5396-99c2-420f-92ec-50ceaa78460a",
   "metadata": {},
   "source": [
    "We are now ready to construct our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a58efe-2b4b-4782-b18f-e2cbde46deb0",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6077e689-30f4-4f8b-bb7f-c3f61654d00c",
   "metadata": {},
   "source": [
    "Back to [Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb370d0-1403-409d-91df-d11c6a56db2b",
   "metadata": {},
   "source": [
    "Fine-tuning BERT is fairly easy, which is one of its primary innovations.\n",
    "The architecture will send the inputs through BERT and get the sequence output,\n",
    "which represents an embedding for each input token.\n",
    "\n",
    "In addition to `sequence_output` there is also `pooled_output` and `encoder_output`, see [Using the BERT model](https://www.tensorflow.org/text/tutorials/classify_text_with_bert#using_the_bert_model) in Classify text with BERT for info about these outputs. We want the `sequence_output` because we want to make a prediction for each token and pick the best one.\n",
    "\n",
    "These embeddings then get sent to a start and and end output that gets flattened.\n",
    "The flattend outputs are then sent to [softmax](https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/softmax), which can represent the probability that\n",
    "the start/end is at this token.\n",
    "\n",
    "Later we will use `np.argmax` to identify the index with the highest probability and\n",
    "chooes that for our answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07396d52-1529-4340-b55b-09fe4944338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who knows what this does! But AUTO sounds promising so haven't bothered to figure it out\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def softmax(name, inp):\n",
    "    # The input here will be something like (seq_length, hidden)\n",
    "    # So we'll wind up doing (seq_len, hidden) * (hidden, 1)\n",
    "    # and wind up with (seq_len, 1), aka an output for each\n",
    "    # position in the input sequence.\n",
    "    net = tf.keras.layers.Dense(1, name=name, use_bias=False)(inp)\n",
    "    # Flatten this, aka change (seq_len, 1) to (seq_len,)\n",
    "    net = tf.keras.layers.Flatten()(net)\n",
    "    # Now apply softmax, aka an S-ish shape with a min of 0 and max of 1\n",
    "    net = tf.keras.layers.Activation(tf.keras.activations.softmax)(net)\n",
    "    return net\n",
    "    \n",
    "def build_highlighter_model():\n",
    "    \n",
    "    sentence_features = [\n",
    "      'input_word_ids',\n",
    "      'input_type_ids',\n",
    "      'input_mask',\n",
    "    ]\n",
    "    # Input tells the network what it should expect.\n",
    "    # The (None,) here that it will be* a rank 1 tensor of integers\n",
    "    # This represents the input token ids, and should match seq_length\n",
    "    # of 384\n",
    "    # \n",
    "    # *: actually this should be a batch of rank 1 tensors, making this\n",
    "    # a rank two tensor of (batch_size, seq_length).\n",
    "    inp = {\n",
    "        ft: tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name=ft)\n",
    "        for ft in sentence_features\n",
    "    }\n",
    "    # This handle is a URL to a pretrained BERT model.\n",
    "    # It will cause tensorflow_hub load the right architecture\n",
    "    # And preconfigure all the weights.\n",
    "    encodings = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT')(inp)\n",
    "    # \n",
    "    net = encodings['sequence_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    start = softmax('start_logit', net)\n",
    "    end = softmax('end_logit', net)\n",
    "    # so they have a name\n",
    "    outs = {\n",
    "        'label_start': tf.keras.layers.Lambda(tf.identity, name='start_pos')(start),\n",
    "        'label_end': tf.keras.layers.Lambda(tf.identity, name='end_pos')(end),\n",
    "    }\n",
    "    return tf.keras.Model(inputs=inp, outputs=outs, name='highlighter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e387f-173f-47da-b3e4-08155f8f831a",
   "metadata": {},
   "source": [
    "Now let's construct the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d84db3c2-2313-4e32-ac57-4d8fff56b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlighter = build_highlighter_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119dc8cf-12f4-4bcd-b573-a890c5c21d4c",
   "metadata": {},
   "source": [
    "Let's see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1855405-846a-4b30-beda-30ad8a6a5af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"highlighter\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_mask (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_type_ids (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_word_ids (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " BERT (KerasLayer)              {'default': (None,   109482241   ['input_mask[0][0]',             \n",
      "                                768),                             'input_type_ids[0][0]',         \n",
      "                                 'pooled_output': (               'input_word_ids[0][0]']         \n",
      "                                None, 768),                                                       \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, None, 768)                                               \n",
      "                                , (None, None, 768)                                               \n",
      "                                , (None, None, 768)                                               \n",
      "                                , (None, None, 768)                                               \n",
      "                                , (None, None, 768)                                               \n",
      "                                , (None, None, 768)                                               \n",
      "                                , (None, None, 768)                                               \n",
      "                                , (None, None, 768)                                               \n",
      "                                , (None, None, 768)                                               \n",
      "                                , (None, None, 768)                                               \n",
      "                                , (None, None, 768)                                               \n",
      "                                , (None, None, 768)                                               \n",
      "                                ],                                                                \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, None, 768)}                                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, None, 768)    0           ['BERT[0][14]']                  \n",
      "                                                                                                  \n",
      " end_logit (Dense)              (None, None, 1)      768         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " start_logit (Dense)            (None, None, 1)      768         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, None)         0           ['end_logit[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, None)         0           ['start_logit[0][0]']            \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, None)         0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, None)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " end_pos (Lambda)               (None, None)         0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " start_pos (Lambda)             (None, None)         0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,777\n",
      "Trainable params: 109,483,776\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlighter.summary()\n",
    "tf.keras.utils.plot_model(highlighter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d8ac8d-1f8d-426e-8765-5017df64edbd",
   "metadata": {},
   "source": [
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69341493-4bc2-42f3-99a6-55dc4bb9b658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 298\n"
     ]
    }
   ],
   "source": [
    "for ex in filt_valid_ds.batch(1):\n",
    "    predy = highlighter(ex['x']) # Print this to see the prediction for all 384 positions\n",
    "    print(np.argmax(predy['label_start']), np.argmax(predy['label_end']))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bde06e-a087-4719-b411-6d83d3ede0c4",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5fe1fc-c994-4f1f-9546-d62c19d5bddf",
   "metadata": {},
   "source": [
    "Back to [Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f2d3b1-7dc7-40f4-82d1-38bdef6fa620",
   "metadata": {},
   "source": [
    "These will just be random values, now we need to train it to do a better job.\n",
    "\n",
    "The goal of the network is, for example, for the network to predict a start index of 7 and and end index of 15.\n",
    "\n",
    "Ideally this means the start probability at position 7 should be 1 (and everything else 0), and the end probability at position 15 is 1 (and everywhere else zero).\n",
    "\n",
    "The [sparse categorical crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) loss function matches that goal. It is similar to [categorical crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) except that we can just specify `7` and `15` instead of a [one-hot](https://www.tensorflow.org/api_docs/python/tf/one_hot) encoded vector (1 at index 7 and 0 everywhere else).\n",
    "\n",
    "We also make sure to shuffle the training dataset and map the inputs/outputs to what a tensorflow model [expects](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit), namely an `(x,y)` tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a9ca685-550b-4a93-9cd3-21ef30a197cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ds(dataset, batch_size, training):\n",
    "    num_examples = len(list(dataset)) # Maybe there's a faster way to do this...\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(num_examples)\n",
    "        dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(lambda ex: (ex['x'], ex['y']))\n",
    "    dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    return dataset, num_examples\n",
    "\n",
    "\n",
    "def train(model, batch_size, epochs, init_lr):\n",
    "    print('Preparing validation data...')\n",
    "    vds, valid_len = prepare_ds(filt_valid_ds, batch_size, training=False)\n",
    "    print('Preparing training data...')\n",
    "    tds, train_len = prepare_ds(filt_train_ds, batch_size, training=True)\n",
    "    steps_per_epoch = train_len / batch_size\n",
    "    num_train_steps = steps_per_epoch * epochs\n",
    "    num_warmup_steps = num_train_steps / 10\n",
    "    validation_steps = valid_len / batch_size\n",
    "    print('Ready to train!')\n",
    "    \n",
    "    with default_strategy.scope():\n",
    "        optimizer = optimization.create_optimizer(\n",
    "            init_lr=init_lr,\n",
    "            num_train_steps=num_train_steps,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            optimizer_type='adamw',\n",
    "        )\n",
    "\n",
    "        loss = {\n",
    "            'label_start': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "            'label_end': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        }\n",
    "\n",
    "        metrics = ['accuracy']\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        model.fit(\n",
    "            x=tds,\n",
    "            validation_data=vds,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=epochs,\n",
    "            validation_steps=validation_steps,\n",
    "        )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14740807-d379-4b3d-a7f8-bf483dbd23ac",
   "metadata": {},
   "source": [
    "Now we are ready to run our training program, choosing a couple of hyperparameters:\n",
    "* `epochs`: how many times the model should see each training data\n",
    "  - We choose `3`, matching the BERT paper\n",
    "* `batch_size`: how many examples to compute in each mini-batch\n",
    "  - largely constrained by GPU RAM\n",
    "  - We choose `16` instead of `32` that the BERT paper uses\n",
    "* `init_lr`: the initial learning rate, which controls how fast it adjusts weights\n",
    "  - Choose `5e-5` to match the BERT paper\n",
    "  \n",
    "Each epoch takes around `1h` to complete on the full dataset.\n",
    "\n",
    "NOTE: you can open up a terminal and use `nvidia-smi -l` to monitor stats about the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84b2e825-c613-4e7f-8017-376811f64450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing validation data...\n",
      "Preparing training data...\n",
      "Ready to train!\n",
      "Epoch 1/3\n",
      "5404/5404 [==============================] - 2563s 471ms/step - loss: 3.0519 - end_pos_loss: 1.5083 - start_pos_loss: 1.5436 - end_pos_accuracy: 0.6069 - start_pos_accuracy: 0.5846 - val_loss: 1.9796 - val_end_pos_loss: 0.9585 - val_start_pos_loss: 1.0210 - val_end_pos_accuracy: 0.7285 - val_start_pos_accuracy: 0.6936\n",
      "Epoch 2/3\n",
      "5404/5404 [==============================] - 2544s 471ms/step - loss: 1.5042 - end_pos_loss: 0.7115 - start_pos_loss: 0.7927 - end_pos_accuracy: 0.7868 - start_pos_accuracy: 0.7514 - val_loss: 1.9589 - val_end_pos_loss: 0.9489 - val_start_pos_loss: 1.0100 - val_end_pos_accuracy: 0.7375 - val_start_pos_accuracy: 0.7049\n",
      "Epoch 3/3\n",
      "5404/5404 [==============================] - 2547s 471ms/step - loss: 0.8887 - end_pos_loss: 0.4112 - start_pos_loss: 0.4775 - end_pos_accuracy: 0.8675 - start_pos_accuracy: 0.8377 - val_loss: 2.2509 - val_end_pos_loss: 1.0983 - val_start_pos_loss: 1.1526 - val_end_pos_accuracy: 0.7398 - val_start_pos_accuracy: 0.7037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 03:18:32.290384: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=highlighter,\n",
    "    epochs=3,\n",
    "    batch_size=16,\n",
    "    init_lr=5e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7220c0b9-7294-4c1c-b7be-c8436139ac64",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87be1d38-d079-4f2c-97f2-d32d9f52bcb3",
   "metadata": {},
   "source": [
    "We are done! Let's first save the model so we can reload/distribute it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75f70c08-ed18-4027-b8ae-cf1e0da45b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(tfds_name='squad'):\n",
    "    main_save_path = './my_models'\n",
    "    bert_type = tfhub_handle_encoder.split('/')[-2]\n",
    "    saved_model_name = f'{tfds_name.replace(\"/\", \"_\")}_{bert_type}'\n",
    "\n",
    "    saved_model_path = os.path.join(main_save_path, saved_model_name)\n",
    "\n",
    "    print('Saving', saved_model_path)\n",
    "\n",
    "    # Save everything on the Colab host (even the variables from TPU memory)\n",
    "    save_options = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "    highlighter.save(saved_model_path, include_optimizer=True,options=save_options)\n",
    "    return saved_model_path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1280182a-d544-446b-9312-993638c70124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ./my_models/squad_bert_en_uncased_L-12_H-768_A-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 03:18:34.449046: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 366). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./my_models/squad_bert_en_uncased_L-12_H-768_A-12/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./my_models/squad_bert_en_uncased_L-12_H-768_A-12/assets\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "942b4166-c266-4ee3-a47b-dbf2ecb4a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/job:localhost'):\n",
    "    default_model_path = './my_models/squad_bert_en_uncased_L-12_H-768_A-12'\n",
    "    reloaded_model = tf.saved_model.load(globals().get('saved_model_path', default_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a43b7d8-f9d2-404d-a4eb-7713c6bb9391",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2baf2c3-c25d-4413-9c2d-dbf10246b1e5",
   "metadata": {},
   "source": [
    "Back to [Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c45dc-f51f-4b1a-b3e2-e2f809b3fbd0",
   "metadata": {},
   "source": [
    "Let's write a function to see how our model performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9cb577e0-b0f9-4f4e-b879-f15e172461cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(xs, true_ys=None, stop=None, batch=16, model=reloaded_model):\n",
    "    ds = tf.data.Dataset.from_tensor_slices({'x': xs, 'y': true_ys}).batch(batch)\n",
    "    for i, batch in enumerate(ds):\n",
    "        x = batch['x']\n",
    "        pred = model(x)\n",
    "        y = {k: np.argmax(pred[k], 1) for k in ['label_start', 'label_end']}\n",
    "        true_y = batch.get('y')\n",
    "        if i == 0:\n",
    "            print('INPUT')\n",
    "            print(ex)\n",
    "            print('RAW OUTPUT PREDICTIONS')\n",
    "            print(pred)\n",
    "            print('ARGMAX OUTPUT')\n",
    "            print(y) \n",
    "            print('='*40)\n",
    "        decode_x(x, y, true_y)\n",
    "        if i == stop:\n",
    "            print('Stopping early')\n",
    "            break\n",
    "    else:\n",
    "        print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04908b3f-39ae-4daa-99c4-6ceff5db4952",
   "metadata": {},
   "source": [
    "Let's first try it on the examples it trained about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15fe7b4d-4f7b-4b16-954f-e676afc4d938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example\n",
      "================================================================================\n",
      "INPUT\n",
      "{'x': {'input_word_ids': <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
      "array([[  101,  1996, 11130,  5402,  4627,  2011,  2478,  1996,  9007,\n",
      "        14548,  2483,  3597,  2000,  8081,  2522,  2475,  2046,  2274,\n",
      "         1011,  6351, 19395, 18845,  3366, 20377,  8458,  2891, 24556,\n",
      "         1006, 14548,  2361,  1007, 10737,  1012,  1996,  2765,  2003,\n",
      "        14480,  2416,  1011,  6351, 10737,  2008,  3202,  3338,  2091,\n",
      "         2046,  2093,  1011,  6351, 10737,  2170,  1017,  1011,  6887,\n",
      "         2891,  8458,  8649,  2135, 17119,  2594,  5648,  1010,  2030,\n",
      "         1017,  1011, 14198,  1012,  1996, 12649,  1998, 23233,  8458,\n",
      "         2081,  1999,  1996,  2422,  9597,  2003,  2109,  2000, 10463,\n",
      "         1996,  1017,  1011, 14198,  2046,  1043,  2135, 19357, 17920,\n",
      "        10536,  3207,  1011,  1017,  1011, 17344,  1010,  2030,  1043,\n",
      "         2509,  2361,  5699, 10737,  1012,  2087,  1997,  1996,  1043,\n",
      "         2509,  2361, 10737,  2024, 22207,  2067,  2046, 14548,  2361,\n",
      "         2478,  2943,  2013,  2062, 12649,  1010,  2021,  2028,  2041,\n",
      "         1997,  2296,  2416,  2550,  3727,  1996,  5402,  1517,  1996,\n",
      "         2203,  4031,  1997,  1996,  2601,  9597,  1012,   102,  2129,\n",
      "         2116,  1043,  2509,  2361, 10737,  2681,  1996,  5402,  1029,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0]], dtype=int32)>, 'input_type_ids': <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'input_mask': <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}, 'y': {'label_start': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([124], dtype=int32)>, 'label_end': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([129], dtype=int32)>}}\n",
      "RAW OUTPUT PREDICTIONS\n",
      "{'label_start': <tf.Tensor: shape=(4, 384), dtype=float32, numpy=\n",
      "array([[1.3775173e-08, 5.4754050e-09, 2.7327345e-09, ..., 1.7641251e-11,\n",
      "        2.0257490e-11, 1.8974265e-11],\n",
      "       [2.7282024e-07, 6.0427665e-06, 3.7759045e-07, ..., 1.0051568e-08,\n",
      "        1.0095836e-08, 9.4805435e-09],\n",
      "       [2.7845081e-06, 3.7674628e-05, 3.4956381e-06, ..., 1.4639417e-08,\n",
      "        1.6492221e-08, 1.5011068e-08],\n",
      "       [8.1614022e-09, 6.1921838e-08, 6.5514733e-08, ..., 1.2016477e-10,\n",
      "        1.1989919e-10, 1.2278258e-10]], dtype=float32)>, 'label_end': <tf.Tensor: shape=(4, 384), dtype=float32, numpy=\n",
      "array([[6.6375294e-10, 3.0114993e-09, 3.4727904e-10, ..., 1.2823428e-11,\n",
      "        1.5706318e-11, 1.5238482e-11],\n",
      "       [5.9379963e-09, 6.8771861e-08, 1.7267745e-08, ..., 1.6107186e-09,\n",
      "        1.7249665e-09, 1.8655781e-09],\n",
      "       [3.6300023e-07, 1.6177834e-06, 1.4979568e-06, ..., 1.9733658e-08,\n",
      "        1.9741789e-08, 2.0810004e-08],\n",
      "       [1.0454790e-09, 5.8426251e-09, 1.1130572e-09, ..., 6.4442618e-11,\n",
      "        7.3275587e-11, 9.3045502e-11]], dtype=float32)>}\n",
      "ARGMAX OUTPUT\n",
      "{'label_start': array([ 75, 184,  61,  95]), 'label_end': array([ 77, 185,  66, 100])}\n",
      "========================================\n",
      "the difference in the above factors for the case of θ = 0 is the reason that most broadcasting ( transmissions intended for the public ) uses vertical polarization . for receivers near the ground , horizontally polarized transmissions suffer cancellation . for best reception the receiving antennas for these signals are likewise vertically polarized . in some applications where the receiving antenna must work in any position , as in mobile phones , the base station antennas use mixed polarization , such as linear polarization at an angle ( with both vertical and horizontal components ) or circular polarization .\n",
      "\n",
      " what is one use that would require an antenna to receive signals in various ways at once ? mobile phones (GTRUTH: mobile phones)\n",
      "----------------------------------------\n",
      "the coronation of charlemagne as emperor on christmas day 800 is regarded as a turning point in medieval history , marking a return of the western roman empire , since the new emperor ruled over much of the area previously controlled by the western emperors . it also marks a change in charlemagne ' s relationship with the byzantine empire , as the assumption of the imperial title by the carolingians asserted their equivalence to the byzantine state . there were several differences between the newly established carolingian empire and both the older western roman empire and the concurrent byzantine empire . the frankish lands were rural in character , with only a few small cities . most of the people were peasants settled on small farms . little trade existed and much of that was with the british isles and scandinavia , in contrast to the older roman empire with its trading networks centred on the mediterranean . the empire was administered by an itinerant court that travelled with the emperor , as well as approximately 300 imperial officials called counts , who administered the counties the empire had been divided into . clergy and local bishops served as officials , as well as the imperial officials called missi dominici , who served as roving inspectors and troubleshooters .\n",
      "\n",
      " about how many counts existed in the carolingian empire ? 300 (GTRUTH: 300)\n",
      "----------------------------------------\n",
      "plant responses to climate and other environmental changes can inform our understanding of how these changes affect ecosystem function and productivity . for example , plant phenology can be a useful proxy for temperature in historical climatology , and the biological impact of climate change and global warming . palynology , the analysis of fossil pollen deposits in sediments from thousands or millions of years ago allows the reconstruction of past climates . estimates of atmospheric co2 concentrations since the palaeozoic have been obtained from stomatal densities and the leaf shapes and sizes of ancient land plants . ozone depletion can expose plants to higher levels of ultraviolet radiation - b ( uv - b ) , resulting in lower growth rates . moreover , information from studies of community ecology , plant systematics , and taxonomy is essential to understanding vegetation change , habitat destruction and species extinction .\n",
      "\n",
      " how can climate changes be determined from soil ? fossil pollen deposits in sediments (GTRUTH: fossil pollen deposits in sediments)\n",
      "----------------------------------------\n",
      "the tucson metro area is served by many local television stations and is the 68th largest designated market area ( dma ) in the u . s . with 433 , 310 homes ( 0 . 39 % of the total u . s . ) . it is limited to the three counties of southeastern arizona ( pima , santa cruz , and cochise ) the major television networks serving tucson are : kvoa 4 ( nbc ) , kgun 9 ( abc ) , kmsb - tv 11 ( fox ) , kold - tv 13 ( cbs ) , kttu 18 ( my network tv ) and kwba 58 ( the cw ) . kuat - tv 6 is a pbs affiliate run by the university of arizona ( as is sister station kuas 27 ) .\n",
      "\n",
      " what is tucson ' s fox station ? kmsb - tv 11 (GTRUTH: kmsb - tv 11)\n",
      "situated on one of the world ' s largest natural harbors , new york city consists of five boroughs , each of which is a separate county of new york state . the five boroughs – brooklyn , queens , manhattan , the bronx , and staten island – were consolidated into a single city in 1898 . with a census - estimated 2014 population of 8 , 491 , 079 distributed over a land area of just 305 square miles ( 790 km2 ) , new york is the most densely populated major city in the united states . as many as 800 languages are spoken in new york , making it the most linguistically diverse city in the world . by 2014 census estimates , the new york city metropolitan region remains by a significant margin the most populous in the united states , as defined by both the metropolitan statistical area ( 20 . 1 million residents ) and the combined statistical area ( 23 . 6 million residents ) . in 2013 , the msa produced a gross metropolitan product ( gmp ) of nearly us $ 1 . 39 trillion , while in 2012 , the csa generated a gmp of over us $ 1 . 55 trillion , both ranking first nationally by a wide margin and behind the gdp of only twelve and eleven countries , respectively .\n",
      "\n",
      " what is the size of new york city in square miles ? 305 (GTRUTH: 305)\n",
      "----------------------------------------\n",
      "similarly , movies and television often revert to standard , cliched snatches of classical music to convey refinement or opulence : some of the most - often heard pieces in this category include bach´s cello suite no . 1 , mozart ' s eine kleine nachtmusik , vivaldi ' s four seasons , mussorgsky ' s night on bald mountain ( as orchestrated by rimsky - korsakov ) , and rossini ' s william tell overture .\n",
      "\n",
      " who wrote william tell overture ? rossini (GTRUTH: rossini)\n",
      "----------------------------------------\n",
      "the fed then raised the fed funds rate significantly between july 2004 and july 2006 . this contributed to an increase in 1 - year and 5 - year adjustable - rate mortgage ( arm ) rates , making arm interest rate resets more expensive for homeowners . this may have also contributed to the deflating of the housing bubble , as asset prices generally move inversely to interest rates , and it became riskier to speculate in housing . u . s . housing and financial assets dramatically declined in value after the housing bubble burst .\n",
      "\n",
      " how do asset prices generally move in relation to interest rates ? inversely (GTRUTH: inversely)\n",
      "----------------------------------------\n",
      "before signing a developmental agreement with the kane county cougars in 2012 , the cubs had a class a minor league affiliation on two occasions with the peoria chiefs ( 1985 – 1995 and 2004 – 2012 ) . ryne sandberg managed the chiefs from 2006 to 2010 . in the period between those associations with the chiefs the club had affiliations with the dayton dragons and lansing lugnuts . the lugnuts were often affectionately referred to by chip caray as \" steve stone ' s favorite team . \" the 2007 developmental contract with the tennessee smokies was preceded by double a affiliations with the orlando cubs and west tenn diamond jaxx . on september 16 , 2014 the cubs announced a move of their top class a affiliate from daytona in the florida state league to myrtle beach in the carolina league for the 2015 season . two days later , on the 18th , the cubs signed a 4 - year player development contract with the south bend silver hawks of the midwest league , ending their brief relationship with the kane county cougars and shortly thereafter renaming the silver hawks the south bend cubs .\n",
      "\n",
      " when did the cubs announce a move of their top class a affiliate from daytona to myrtle beach ? september 16 , 2014 (GTRUTH: september 16 , 2014)\n",
      "Stopping early\n"
     ]
    }
   ],
   "source": [
    "print('Training example')\n",
    "print('='*80)\n",
    "evaluate(train_x,train_y, stop=1, batch=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a6cd66-c33b-482d-ad3b-0a18037fc7ef",
   "metadata": {},
   "source": [
    "Now let's see how it does against the validation data it never saw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebfbbd65-46fb-4174-8080-865178ae3f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation example\n",
      "================================================================================\n",
      "INPUT\n",
      "{'x': {'input_word_ids': <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
      "array([[  101,  1996, 11130,  5402,  4627,  2011,  2478,  1996,  9007,\n",
      "        14548,  2483,  3597,  2000,  8081,  2522,  2475,  2046,  2274,\n",
      "         1011,  6351, 19395, 18845,  3366, 20377,  8458,  2891, 24556,\n",
      "         1006, 14548,  2361,  1007, 10737,  1012,  1996,  2765,  2003,\n",
      "        14480,  2416,  1011,  6351, 10737,  2008,  3202,  3338,  2091,\n",
      "         2046,  2093,  1011,  6351, 10737,  2170,  1017,  1011,  6887,\n",
      "         2891,  8458,  8649,  2135, 17119,  2594,  5648,  1010,  2030,\n",
      "         1017,  1011, 14198,  1012,  1996, 12649,  1998, 23233,  8458,\n",
      "         2081,  1999,  1996,  2422,  9597,  2003,  2109,  2000, 10463,\n",
      "         1996,  1017,  1011, 14198,  2046,  1043,  2135, 19357, 17920,\n",
      "        10536,  3207,  1011,  1017,  1011, 17344,  1010,  2030,  1043,\n",
      "         2509,  2361,  5699, 10737,  1012,  2087,  1997,  1996,  1043,\n",
      "         2509,  2361, 10737,  2024, 22207,  2067,  2046, 14548,  2361,\n",
      "         2478,  2943,  2013,  2062, 12649,  1010,  2021,  2028,  2041,\n",
      "         1997,  2296,  2416,  2550,  3727,  1996,  5402,  1517,  1996,\n",
      "         2203,  4031,  1997,  1996,  2601,  9597,  1012,   102,  2129,\n",
      "         2116,  1043,  2509,  2361, 10737,  2681,  1996,  5402,  1029,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0]], dtype=int32)>, 'input_type_ids': <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'input_mask': <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}, 'y': {'label_start': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([124], dtype=int32)>, 'label_end': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([129], dtype=int32)>}}\n",
      "RAW OUTPUT PREDICTIONS\n",
      "{'label_start': <tf.Tensor: shape=(4, 384), dtype=float32, numpy=\n",
      "array([[7.9713851e-07, 6.8065315e-06, 6.9302027e-06, ..., 4.0772328e-09,\n",
      "        4.5020458e-09, 4.2116035e-09],\n",
      "       [1.4316373e-08, 2.4044407e-06, 2.9547058e-05, ..., 7.5148543e-10,\n",
      "        8.0132034e-10, 7.7770695e-10],\n",
      "       [1.9486856e-06, 2.3381597e-06, 5.5403962e-07, ..., 1.0670606e-08,\n",
      "        1.0491897e-08, 1.2599599e-08],\n",
      "       [6.5199846e-09, 3.1212454e-05, 1.8025337e-05, ..., 5.9238385e-11,\n",
      "        6.0451255e-11, 6.1993029e-11]], dtype=float32)>, 'label_end': <tf.Tensor: shape=(4, 384), dtype=float32, numpy=\n",
      "array([[8.2972960e-08, 5.2148303e-06, 1.1168443e-06, ..., 1.5799642e-08,\n",
      "        1.5582279e-08, 1.5674118e-08],\n",
      "       [5.1198832e-09, 1.3701441e-06, 1.1166538e-06, ..., 1.9532176e-09,\n",
      "        1.8283834e-09, 1.8837008e-09],\n",
      "       [1.0853330e-06, 8.1778796e-07, 1.2190253e-07, ..., 3.3335574e-08,\n",
      "        3.5243310e-08, 2.8378221e-08],\n",
      "       [5.7410098e-11, 3.3586358e-07, 7.3942864e-08, ..., 1.7615916e-11,\n",
      "        1.7192915e-11, 1.7141507e-11]], dtype=float32)>}\n",
      "ARGMAX OUTPUT\n",
      "{'label_start': array([124,  44, 158,   7]), 'label_end': array([129,  50, 167,   9])}\n",
      "========================================\n",
      "the calvin cycle starts by using the enzyme rubisco to fix co2 into five - carbon ribulose bisphosphate ( rubp ) molecules . the result is unstable six - carbon molecules that immediately break down into three - carbon molecules called 3 - phosphoglyceric acid , or 3 - pga . the atp and nadph made in the light reactions is used to convert the 3 - pga into glyceraldehyde - 3 - phosphate , or g3p sugar molecules . most of the g3p molecules are recycled back into rubp using energy from more atp , but one out of every six produced leaves the cycle — the end product of the dark reactions .\n",
      "\n",
      " how many g3p molecules leave the cycle ? one out of every six (GTRUTH: one out of every six)\n",
      "----------------------------------------\n",
      "a cylindrical service module ( sm ) supported the command module , with a service propulsion engine and an rcs with propellants , and a fuel cell power generation system with liquid hydrogen and liquid oxygen reactants . a high - gain s - band antenna was used for long - distance communications on the lunar flights . on the extended lunar missions , an orbital scientific instrument package was carried . the service module was discarded just before re - entry . the module was 24 . 6 feet ( 7 . 5 m ) long and 12 . 83 feet ( 3 . 91 m ) in diameter . the initial lunar flight version weighed approximately 51 , 300 pounds ( 23 , 300 kg ) fully fueled , while a later version designed to carry a lunar orbit scientific instrument package weighed just over 54 , 000 pounds ( 24 , 000 kg ) .\n",
      "\n",
      " what type of antenna was used for communication on the lunar flights ? high - gain s - band (GTRUTH: high - gain s - band antenna)\n",
      "----------------------------------------\n",
      "the addition of new rock units , both depositionally and intrusively , often occurs during deformation . faulting and other deformational processes result in the creation of topographic gradients , causing material on the rock unit that is increasing in elevation to be eroded by hillslopes and channels . these sediments are deposited on the rock unit that is going down . continual motion along the fault maintains the topographic gradient in spite of the movement of sediment , and continues to create accommodation space for the material to deposit . deformational events are often also associated with volcanism and igneous activity . volcanic ashes and lavas accumulate on the surface , and igneous intrusions enter from below . dikes , long , planar igneous intrusions , enter along cracks , and therefore often form in large numbers in areas that are being actively deformed . this can result in the emplacement of dike swarms , such as those that are observable across the canadian shield , or rings of dikes around the lava tube of a volcano .\n",
      "\n",
      " where do dikes form ? in areas that are being actively deformed (GTRUTH: in areas that are being actively deformed)\n",
      "----------------------------------------\n",
      "the mouth of the rhine into lake constance forms an inland delta . the delta is delimited in the west by the alter rhein ( \" old rhine \" ) and in the east by a modern canalized section . most of the delta is a nature reserve and bird sanctuary . it includes the austrian towns of gaißau , hochst and fußach . the natural rhine originally branched into at least two arms and formed small islands by precipitating sediments . in the local alemannic dialect , the singular is pronounced \" isel \" and this is also the local pronunciation of esel ( \" donkey \" ) . many local fields have an official name containing this element .\n",
      "\n",
      " the inland delta at the mouth of the rhine is with what lake ? lake constance (GTRUTH: lake constance)\n",
      "a computational problem can be viewed as an infinite collection of instances together with a solution for every instance . the input string for a computational problem is referred to as a problem instance , and should not be confused with the problem itself . in computational complexity theory , a problem refers to the abstract question to be solved . in contrast , an instance of this problem is a rather concrete utterance , which can serve as the input for a decision problem . for example , consider the problem of primality testing . the instance is a number ( e . g . 15 ) and the solution is \" yes \" if the number is prime and \" no \" otherwise ( in this case \" no \" ) . stated another way , the instance is a particular input to the problem , and the solution is the output corresponding to the given input .\n",
      "\n",
      " is a problem instance typically characterized as abstract or concrete ? concrete (GTRUTH: concrete)\n",
      "----------------------------------------\n",
      "paul revere was descended from huguenot refugees , as was henry laurens , who signed the articles of confederation for south carolina ; jack jouett , who made the ride from cuckoo tavern to warn thomas jefferson and others that tarleton and his men were on their way to arrest him for crimes against the king ; francis marion , and a number of other leaders of the american revolution and later statesmen . the last active huguenot congregation in north america worships in charleston , south carolina , at a church that dates to 1844 . the huguenot society of america maintains manakin episcopal church in virginia as an historic shrine with occasional services . the society has chapters in numerous states , with the one in texas being the largest .\n",
      "\n",
      " in what state is the largest huguenot society located ? texas (GTRUTH: texas)\n",
      "----------------------------------------\n",
      "in land plants , chloroplasts are generally lens - shaped , 5 – 8 μm in diameter and 1 – 3 μm thick . greater diversity in chloroplast shapes exists among the algae , which often contain a single chloroplast that can be shaped like a net ( e . g . , oedogonium ) , a cup ( e . g . , chlamydomonas ) , a ribbon - like spiral around the edges of the cell ( e . g . , spirogyra ) , or slightly twisted bands at the cell edges ( e . g . , sirogonium ) . some algae have two chloroplasts in each cell ; they are star - shaped in zygnema , or may follow the shape of half the cell in order desmidiales . in some algae , the chloroplast takes up most of the cell , with pockets for the nucleus and other organelles ( for example some species of chlorella have a cup - shaped chloroplast that occupies much of the cell ) .\n",
      "\n",
      " how thick are chloroplasts in land plants ? 1 – 3 μm (GTRUTH: 1 – 3 μm)\n",
      "----------------------------------------\n",
      "the fucoxanthin dinophyte lineages ( including karlodinium and karenia ) lost their original red algal derived chloroplast , and replaced it with a new chloroplast derived from a haptophyte endosymbiont . karlodinium and karenia probably took up different heterokontophytes . because the haptophyte chloroplast has four membranes , tertiary endosymbiosis would be expected to create a six membraned chloroplast , adding the haptophyte ' s cell membrane and the dinophyte ' s phagosomal vacuole . however , the haptophyte was heavily reduced , stripped of a few membranes and its nucleus , leaving only its chloroplast ( with its original double membrane ) , and possibly one or two additional membranes around it .\n",
      "\n",
      " what lineage is karenia in ? fucoxanthin dinophyte (GTRUTH: fucoxanthin dinophyte)\n",
      "Stopping early\n"
     ]
    }
   ],
   "source": [
    "print('Validation example')\n",
    "print('='*80)\n",
    "evaluate(valid_x, valid_y, stop=1, batch=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e9f5cd-e14e-4c5d-94ee-9bbf57ac70ff",
   "metadata": {},
   "source": [
    "Now let's try some really random data it has not seen. Here is a paragraph taken from the [spyglass](https://github.com/kubernetes/test-infra/tree/master/prow/spyglass) and its [lens](https://github.com/kubernetes/test-infra/blob/master/prow/spyglass/write-a-lens.md) documentation for [prow](https://github.com/kubernetes/test-infra/tree/master/prow) as well as [testgrid](https://github.com/GoogleCloudPlatform/testgrid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efd592d3-e9bf-4fcb-b85c-94fa21f025c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to help write multiple questions about a single context paragraph.\n",
    "def user_dataset(contexts):\n",
    "    \"\"\"Converts a [(ctx, (q1, q2, q3)), ...] into [{'context': ctx, 'question': q1}].\"\"\"\n",
    "    for context, questions in contexts:\n",
    "        for q in questions:\n",
    "            yield {'context': context, 'question': q}\n",
    "            \n",
    "user_ds = user_dataset([\n",
    "    (\n",
    "        '''\n",
    "        Spyglass is a pluggable artifact viewer framework for Prow.\n",
    "        It collects artifacts (usually files in a storage bucket) from various sources and distributes them to registered viewers,\n",
    "        which are responsible for consuming them and rendering a view.\n",
    "        ''',\n",
    "        (\n",
    "            'What does spyglass collect?',\n",
    "            'Where does spyglass collect artifacts from?',\n",
    "            'What is spyglass?',\n",
    "            'What are the registered viewers responsible for?',\n",
    "            'What is spyglass a framework for?',\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        '''\n",
    "        The HTML generated by a lens can reference static assets that will be served by Deck on behalf of your lens.\n",
    "        Scripts and stylesheets can be referenced in the output of the Header() function\n",
    "        (which is inserted into the <head> element).\n",
    "        Relative references into your directory will work:\n",
    "          spyglass adds a <base> tag that references the expected output directory.\n",
    "        \n",
    "        Spyglass lenses have access to a spyglass global that provides a number of APIs\n",
    "        to interact with your lens backend and the rest of the world.\n",
    "        Your lens is rendered in a sandboxed iframe, so you generally cannot interact without using these APIs.\n",
    "        ''',\n",
    "        (\n",
    "            'What can lenses reference?',\n",
    "            'What serves the HTML generated by the lens?',\n",
    "            'How do relative references work?',\n",
    "            'What provides the spyglass APIs?',\n",
    "            'What do the spyglass APIs allow?',\n",
    "            'Where is your lens rendered?',\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        '''\n",
    "        Fragment URLs (the part after the #) are supported fairly transparently, despite being in an iframe.\n",
    "        The parent page muxes all the lens's fragments and ensures that if the page is loaded,\n",
    "        each lens receives the fragment it expects.\n",
    "        Changing your fragment will automatically update the parent page's fragment.\n",
    "        If the fragment matches the ID or name of an element, the page will scroll such that that element is visible.\n",
    "\n",
    "        Anchor links (<a href=\"#something\">) would usually not work well in conjunction with the <base> tag.\n",
    "        To resolve this, we rewrite all links of this form to behave as expected both on page load and on DOM modification.\n",
    "        In most cases, this should be transparent.\n",
    "        If you want users to copy links via right click -> copy link, however, this will not work nicely.\n",
    "        Instead, consider setting the href attribute to something from spyglass.makeFragmentLink,\n",
    "        but handling clicks by manually setting location.hash to the desired fragment.\n",
    "        ''',\n",
    "        (\n",
    "            'What is a fragment URL?',\n",
    "            'When a fragment matches the ID, what does the page do?',\n",
    "            'How well does copying via right click work?',\n",
    "            'What should you set the href attribute to?',\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        '''\n",
    "        The three sizes are Standard, Compact, and Super Compact.\n",
    "        You can also specify width=X in the URL (X > 3) to customize the width.\n",
    "        For small widths, this may mean the date and/or changelist, or other custom headers, are no longer visible.\n",
    "        ''',\n",
    "        (\n",
    "            'How many sizes are there?',\n",
    "            'How do you customize the width?',\n",
    "            'What might happen when the width is small?',\n",
    "        ),\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faaea0c-ffec-4338-8600-43bc5253a655",
   "metadata": {},
   "source": [
    "Note that there are no known answers to the questions above. How well will it answer these questions?\n",
    "\n",
    "Let's repackage and process the above questions into a `user_x` and `user_y` that we can send into evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3157baf0-80de-46bd-930f-96811436b1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Done!\n"
     ]
    }
   ],
   "source": [
    "def repackage():\n",
    "    out = {}\n",
    "    for ex in user_ds:\n",
    "        for key in ex:\n",
    "            out.setdefault(key, []).append(ex[key])\n",
    "            \n",
    "    return out\n",
    "\n",
    "\n",
    "raw_user_ds = tf.data.Dataset.from_tensor_slices(repackage())\n",
    "user_x, user_y = process_examples(raw_user_ds)\n",
    "\n",
    "user_ds = tf.data.Dataset.from_tensor_slices({'x': user_x})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6186940-e609-4383-8589-05114587849b",
   "metadata": {},
   "source": [
    "Now let's see it's predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eebfe1a6-d630-4417-8ba2-0591a75c7d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT\n",
      "{'x': {'input_word_ids': <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
      "array([[  101,  1996, 11130,  5402,  4627,  2011,  2478,  1996,  9007,\n",
      "        14548,  2483,  3597,  2000,  8081,  2522,  2475,  2046,  2274,\n",
      "         1011,  6351, 19395, 18845,  3366, 20377,  8458,  2891, 24556,\n",
      "         1006, 14548,  2361,  1007, 10737,  1012,  1996,  2765,  2003,\n",
      "        14480,  2416,  1011,  6351, 10737,  2008,  3202,  3338,  2091,\n",
      "         2046,  2093,  1011,  6351, 10737,  2170,  1017,  1011,  6887,\n",
      "         2891,  8458,  8649,  2135, 17119,  2594,  5648,  1010,  2030,\n",
      "         1017,  1011, 14198,  1012,  1996, 12649,  1998, 23233,  8458,\n",
      "         2081,  1999,  1996,  2422,  9597,  2003,  2109,  2000, 10463,\n",
      "         1996,  1017,  1011, 14198,  2046,  1043,  2135, 19357, 17920,\n",
      "        10536,  3207,  1011,  1017,  1011, 17344,  1010,  2030,  1043,\n",
      "         2509,  2361,  5699, 10737,  1012,  2087,  1997,  1996,  1043,\n",
      "         2509,  2361, 10737,  2024, 22207,  2067,  2046, 14548,  2361,\n",
      "         2478,  2943,  2013,  2062, 12649,  1010,  2021,  2028,  2041,\n",
      "         1997,  2296,  2416,  2550,  3727,  1996,  5402,  1517,  1996,\n",
      "         2203,  4031,  1997,  1996,  2601,  9597,  1012,   102,  2129,\n",
      "         2116,  1043,  2509,  2361, 10737,  2681,  1996,  5402,  1029,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0]], dtype=int32)>, 'input_type_ids': <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'input_mask': <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}, 'y': {'label_start': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([124], dtype=int32)>, 'label_end': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([129], dtype=int32)>}}\n",
      "RAW OUTPUT PREDICTIONS\n",
      "{'label_start': <tf.Tensor: shape=(16, 384), dtype=float32, numpy=\n",
      "array([[7.2128820e-08, 2.5026566e-05, 1.1244407e-07, ..., 2.5552800e-09,\n",
      "        2.9617127e-09, 3.0284335e-09],\n",
      "       [4.7679492e-07, 1.8578148e-05, 5.7618376e-08, ..., 1.4803204e-09,\n",
      "        1.5699190e-09, 1.5445157e-09],\n",
      "       [3.2502982e-07, 1.2593296e-04, 7.2088845e-08, ..., 3.2306080e-10,\n",
      "        3.3848088e-10, 3.4831005e-10],\n",
      "       ...,\n",
      "       [2.6627487e-07, 9.2488872e-06, 2.4869490e-07, ..., 2.2977359e-08,\n",
      "        2.4254904e-08, 2.5036535e-08],\n",
      "       [5.9828506e-07, 4.4622786e-05, 8.7399667e-07, ..., 1.3525194e-09,\n",
      "        1.4201668e-09, 1.3924883e-09],\n",
      "       [2.0509415e-06, 3.9715830e-02, 9.2756075e-01, ..., 3.7762700e-09,\n",
      "        4.3694346e-09, 4.0100319e-09]], dtype=float32)>, 'label_end': <tf.Tensor: shape=(16, 384), dtype=float32, numpy=\n",
      "array([[1.5947944e-07, 2.4003032e-06, 5.4339716e-07, ..., 6.7103207e-09,\n",
      "        5.8292500e-09, 5.7771388e-09],\n",
      "       [2.6809241e-08, 8.4975198e-07, 1.3257213e-07, ..., 1.0058160e-09,\n",
      "        1.0198874e-09, 1.1475392e-09],\n",
      "       [1.9325979e-07, 2.2749379e-04, 1.1322809e-06, ..., 4.6384185e-09,\n",
      "        4.4569646e-09, 4.5101816e-09],\n",
      "       ...,\n",
      "       [6.4530134e-08, 2.1957965e-07, 1.1956888e-07, ..., 7.4801561e-09,\n",
      "        7.3670390e-09, 6.5897670e-09],\n",
      "       [1.0378906e-08, 1.4147239e-06, 9.1942729e-07, ..., 4.0826018e-10,\n",
      "        3.7275244e-10, 3.8108361e-10],\n",
      "       [8.8245699e-08, 1.5660764e-04, 7.6287200e-05, ..., 1.9227138e-09,\n",
      "        1.7511149e-09, 1.9526010e-09]], dtype=float32)>}\n",
      "ARGMAX OUTPUT\n",
      "{'label_start': array([ 17,  20,   4,  41,  12,   9,  16,  59,  82,  93, 112,   5,  81,\n",
      "       168, 183,   2]), 'label_end': array([ 18,  25,  11,  47,  14,  22,  17,  74,  85, 105, 118,  10,  82,\n",
      "       173, 187,   3])}\n",
      "========================================\n",
      "spyglass is a pluggable artifact viewer framework for prow . it collects artifacts ( usually files in a storage bucket ) from various sources and distributes them to registered viewers , which are responsible for consuming them and rendering a view .\n",
      "\n",
      " what does spyglass collect ? artifacts\n",
      "\n",
      " where does spyglass collect artifacts from ? files in a storage bucket\n",
      "\n",
      " what is spyglass ? a pluggable artifact viewer framework\n",
      "\n",
      " what are the registered viewers responsible for ? consuming them and rendering a view\n",
      "\n",
      " what is spyglass a framework for ? prow\n",
      "----------------------------------------\n",
      "the html generated by a lens can reference static assets that will be served by deck on behalf of your lens . scripts and stylesheets can be referenced in the output of the header ( ) function ( which is inserted into the < head > element ) . relative references into your directory will work : spyglass adds a < base > tag that references the expected output directory . spyglass lenses have access to a spyglass global that provides a number of apis to interact with your lens backend and the rest of the world . your lens is rendered in a sandboxed iframe , so you generally cannot interact without using these apis .\n",
      "\n",
      " what can lenses reference ? static assets that will be served by deck on behalf of your lens\n",
      "\n",
      " what serves the html generated by the lens ? deck\n",
      "\n",
      " how do relative references work ? : spyglass adds a < base > tag that references the expected output directory\n",
      "\n",
      " what provides the spyglass apis ? spyglass global\n",
      "\n",
      " what do the spyglass apis allow ? interact with your lens backend and the rest of the world\n",
      "\n",
      " where is your lens rendered ? sandboxed iframe\n",
      "----------------------------------------\n",
      "fragment urls ( the part after the # ) are supported fairly transparently , despite being in an iframe . the parent page muxes all the lens ' s fragments and ensures that if the page is loaded , each lens receives the fragment it expects . changing your fragment will automatically update the parent page ' s fragment . if the fragment matches the id or name of an element , the page will scroll such that that element is visible . anchor links ( < a href = \" # something \" > ) would usually not work well in conjunction with the < base > tag . to resolve this , we rewrite all links of this form to behave as expected both on page load and on dom modification . in most cases , this should be transparent . if you want users to copy links via right click - > copy link , however , this will not work nicely . instead , consider setting the href attribute to something from spyglass . makefragmentlink , but handling clicks by manually setting location . hash to the desired fragment .\n",
      "\n",
      " what is a fragment url ? the part after the #\n",
      "\n",
      " when a fragment matches the id , what does the page do ? scroll\n",
      "\n",
      " how well does copying via right click work ? this will not work nicely\n",
      "\n",
      " what should you set the href attribute to ? something from spyglass\n",
      "----------------------------------------\n",
      "the three sizes are standard , compact , and super compact . you can also specify width = x in the url ( x > 3 ) to customize the width . for small widths , this may mean the date and / or changelist , or other custom headers , are no longer visible .\n",
      "\n",
      " how many sizes are there ? three\n",
      "the three sizes are standard , compact , and super compact . you can also specify width = x in the url ( x > 3 ) to customize the width . for small widths , this may mean the date and / or changelist , or other custom headers , are no longer visible .\n",
      "\n",
      " how do you customize the width ? width = x in the url ( x > 3 )\n",
      "\n",
      " what might happen when the width is small ? the date and / or changelist , or other custom headers , are no longer visible\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "evaluate(user_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce9800-a23b-4db1-b5f6-bb280642c8d3",
   "metadata": {},
   "source": [
    "Not too bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d39fa-ba60-4935-bdb4-21a71a7a69e7",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c60bc0-29b6-48ec-8807-166abd0f3649",
   "metadata": {},
   "source": [
    "* Get this to run with TPUs instead of GPUs.\n",
    "* Add an [F1 metric](https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1)\n",
    "  - A tensorflow [addon for F1](https://www.tensorflow.org/addons/api_docs/python/tfa/metrics/F1Score)\n",
    "  - SQuADs [F1 score](https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/) script\n",
    "    - Submissions are evaluated using this metric\n",
    "  - Tensorflow callback [on_epoc_end](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_epoch_end)\n",
    "* Update for SQuAD v2 with unanswerable questions\n",
    "  - Make unanswerable target the `[CLS]` position\n",
    "  - [Example](https://qa.fastforwardlabs.com/no%20answer/null%20threshold/bert/distilbert/exact%20match/f1/robust%20predictions/2020/06/09/Evaluating_BERT_on_SQuAD.html#F1) of this activity.\n",
    "* Apply this knowledge to a prow highlighter\n",
    "  - Split document into N pages\n",
    "  - Tokenize each page\n",
    "  - Find the `start, end` token position of each highlight (or `0,0` if no highlight)\n",
    "  - Send tokenized page to BERT\n",
    "  - Send BERT `sequence_output` to `start` and `end` `Dense(1)` outputs that gets flattened and softmaxed\n",
    "  - Choose the highest probability start/end combo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd77809f-2f65-4acb-b6ff-f76d9daef436",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ef8e6-c6e5-4950-98e7-0891119d0719",
   "metadata": {},
   "source": [
    "* BERT paper - https://arxiv.org/abs/1810.04805\n",
    "* [Fine tuning BERT](https://www.tensorflow.org/text/tutorials/fine_tune_bert)\n",
    "  - Shows how to tokenize text in tensorflow2\n",
    "* [Fine tune BERT with GLUE](https://www.tensorflow.org/text/tutorials/bert_glue)\n",
    "  - Shows how to fine tune a BERT model \n",
    "* [Fine Tuning BERT for Text Classification and Question Answering Using TensorFlow Framework](https://medium.com/swlh/fine-tuning-bert-for-text-classification-and-question-answering-using-tensorflow-framework-4d09daeb3330)\n",
    "  - A tensorflow 1 solution for fine tuning BERTG\n",
    "* [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/)\n",
    "  - A reading comprehension dataset."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
